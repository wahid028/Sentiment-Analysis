{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "nltk.download(\"all\")\n",
    "from bs4 import BeautifulSoup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning import seed_everything\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "import torchmetrics\n",
    "from torchmetrics.functional.classification import binary_accuracy, binary_f1_score, binary_precision, binary_recall, binary_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with neutral sentiment as we are only interested in positive and negative sentiment\n",
    "train = train[train['sentiment'] != 'neutral']\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "test = test[test['sentiment'] != 'neutral']\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "#re-arranging the datasets\n",
    "train = train[['text','sentiment']]\n",
    "test = test[['text','sentiment']]\n",
    "\n",
    "#sentiment converter funtion\n",
    "def sentiment_ts(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return 0\n",
    "    elif sentiment == 'positive':\n",
    "        return 1\n",
    "\n",
    "#convert the text sentimnet into number\n",
    "train['label'] = train['sentiment'].apply(sentiment_ts)\n",
    "test['label'] = test['sentiment'].apply(sentiment_ts)\n",
    "\n",
    "#final dataset\n",
    "train = train[['text','label']]\n",
    "test = test[['text','label']]\n",
    "\n",
    "# #sanity check\n",
    "# train.head()\n",
    "# test.head()\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the spacy model and functions related to stop words modification\n",
    "spacy_model = spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as spacy_stopwords\n",
    "# print(spacy_model.Defaults.stop_words) #print the default stop words list\n",
    "# spacy_model.Defaults.stop_words.remove(\"whatever\") #remove single stop word from the list\n",
    "# spacy_model.Defaults.stop_words -= {\"whatever\", \"whenever\"} #remove several stop words from the list\n",
    "# spacy_model.Defaults.stop_words.add(\"my_new_stopword\") #add single stop word in the default list\n",
    "# spacy_model.stop_words |= {\"my_new_stopword1\",\"my_new_stopword2\"} #add several stop words in the default list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most widely used shortforms are in the internet for social media data\n",
    "contra_Expan_Dict = {\n",
    "\"ain`t\": \"am not\",\"aren`t\": \"are not\",\"can`t\": \"cannot\",\"can`t`ve\": \"cannot have\",\"`cause\": \"because\",\n",
    "\"could`ve\": \"could have\",\"couldn`t\": \"could not\",\"couldn`t`ve\": \"could not have\",\"didn`t\": \"did not\",\n",
    "\"doesn`t\": \"does not\",\"don`t\": \"do not\",\"hadn`t\": \"had not\",\"hadn`t`ve\": \"had not have\",\"hasn`t\": \"has not\",\n",
    "\"haven`t\": \"have not\",\"he`d\": \"he would\",\"he`d`ve\": \"he would have\",\"he`ll\": \"he will\",\"he`ll`ve\": \"he will have\",\n",
    "\"he`s\": \"he is\",\"how`d\": \"how did\",\"how`d`y\": \"how do you\",\"how`ll\": \"how will\",\n",
    "\"how`s\": \"how does\",\"i`d\": \"i would\",\"i`d`ve\": \"i would have\",\"i`ll\": \"i will\",\"i`ll`ve\": \"i will have\",\"i`m\": \"i am\",\n",
    "\"i`ve\": \"i have\",\"isn`t\": \"is not\",\"it`d\": \"it would\",\"it`d`ve\": \"it would have\",\"it`ll\": \"it will\",\"it`ll`ve\": \"it will have\",\n",
    "\"it`s\": \"it is\",\"let`s\": \"let us\",\"ma`am\": \"madam\",\"mayn`t\": \"may not\",\"might`ve\": \"might have\",\"mightn`t\": \"might not\",\n",
    "\"mightn`t`ve\": \"might not have\",\"must`ve\": \"must have\",\"mustn`t\": \"must not\",\"mustn`t`ve\": \"must not have\",\"needn`t\": \"need not\",\"needn`t`ve\": \"need not have\",\n",
    "\"o`clock\": \"of the clock\",\"oughtn`t\": \"ought not\",\"oughtn`t`ve\": \"ought not have\",\"shan`t\": \"shall not\",\n",
    "\"sha`n`t\": \"shall not\",\"shan`t`ve\": \"shall not have\",\"she`d\": \"she would\",\n",
    "\"she`d`ve\": \"she would have\",\"she`ll\": \"she will\",\"she`ll`ve\": \"she will have\",\n",
    "\"she`s\": \"she is\",\"should`ve\": \"should have\",\"shouldn`t\": \"should not\",\"shouldn`t`ve\": \"should not have\",\"so`ve\": \"so have\",\"so`s\": \"so is\",\n",
    "\"that`d\": \"that would\",\"that`d`ve\": \"that would have\",\"that`s\": \"that is\",\"there`d\": \"there would\",\"there`d`ve\": \"there would have\",\"there`s\": \"there is\",\n",
    "\"they`d\": \"they would\",\"they`d`ve\": \"they would have\",\"they`ll\": \"they will\",\"they`ll`ve\": \"they will have\",\"they`re\": \"they are\",\"they`ve\": \"they have\",\n",
    "\"to`ve\": \"to have\",\"wasn`t\": \"was not\",\" u \": \" you \",\" ur \": \" your \",\" n \": \" and \",\"won`t\": \"would not\",\n",
    "\"dis\": \"this\",\"bak\": \"back\",\"brng\": \"bring\",\"sooo\": \"so\", \"afaik\" :\"as far as i know\",\n",
    "\"afk\" :\"away from keyboard\",\"asap\" :\"as soon as possible\",\"atk\" :\"at the keyboard\",\"atm\" :\"at the moment\",\"a3\" :\"anytime, anywhere, anyplace\",\n",
    "\"bak\" :\"back at keyboard\",\"bbl\" :\"be back later\",\"bbs\" :\"be back soon\",\"bfn\" :\"bye for now\",\"b4n\" :\"bye for now\",\"brb\" :\"be right back\",\n",
    "\"brt\" :\"be right there\",\"btw\" :\"by the way\",\"b4\" :\"before\",\"b4n\" :\"bye for now\",\"cu\" :\"see you\",\"cul8r\" :\"see you later\",\n",
    "\"cya\" :\"see you\",\"faq\" :\"frequently asked questions\",\"fc\" :\"fingers crossed\",\"fwiw\" :\"for what it's worth\",\"fyi\" :\"for your information\",\n",
    "\"gal\" :\"get a life\",\"gg\" :\"good game\",\"gn\" :\"good night\",\"gmta\" :\"great minds think alike\",\"gr8\" :\"great!\",\"g9\" :\"genius\",\n",
    "\"ic\" :\"i see\",\"icq\" :\"i seek you (also a chat program)\",\"ilu\" :\"ilu: i love you\",\"imho\" :\"in my honest/humble opinion\",\"imo\" :\"in my opinion\",\"iow\" :\"in other words\",\n",
    "\"irl\" :\"in real life\",\"kiss\" :\"keep it simple, stupid\",\"ldr\" :\"long distance relationship\",\"lmao\" :\"laugh my a.. off\",\"lol\" :\"laughing out loud\",\n",
    "\"ltns\" :\"long time no see\",\"l8r\" :\"later\",\"mte\" :\"my thoughts exactly\",\"m8\" :\"mate\",\"nrn\" :\"no reply necessary\",\"oic\" :\"oh i see\",\n",
    "\"pita\" :\"pain in the a..\",\"prt\" :\"party\",\"prw\" :\"parents are watching\",\"qpsa?   que pasa?\" :\"\",\"rofl\" :\"rolling on the floor laughing\",\n",
    "\"roflol\" :\"rolling on the floor laughing out loud\",\"rotflmao\" :\"rolling on the floor laughing my ass off\",\"sk8\" :\"skate\",\"stats\" :\"your sex and age\",\n",
    "\"asl\" :\"age, sex, location\",\"thx\" :\"thank you\",\"ttfn\" :\"ta-ta for now!\",\"ttyl\" :\"talk to you later\",\n",
    "\"u\" :\"you\",\"u2\" :\"you too\",\"u4e\" :\"yours for ever\",\"wb\" :\"welcome back\",\"wtf\" :\"what the fuck\",\"wtg\" :\"way to go!\",\n",
    "\"wuf\" :\"where are you from?\",\"w8\" :\"wait\",\"7k\" :\"sick:-d laugher\", \"w/out\": \"without\", \"ihavent\": \"i have not\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for converting shortforms to it's expanded form based on contra_Expan_Dict\n",
    "def expanded_form(x):\n",
    "  if x in contra_Expan_Dict.keys():\n",
    "    return(contra_Expan_Dict[x])\n",
    "  else:\n",
    "    return(x)\n",
    "\n",
    "#function for removing url punctuations and digits\n",
    "def clean_with_re(x):\n",
    "  x=str(x)\n",
    "  x=re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\" \", x) #Remove URLs\n",
    "  x=re.sub(r'[^\\w ]+', \"\", x) # Remove Punctuation-1\n",
    "  x=re.sub(r\"[,!@&\\'?\\.$%_]\",\" \", x) # Remove Punctuation-2\n",
    "  x=re.sub(r\"\\d+\",\" \", x) #Remove digits\n",
    "  return(x)\n",
    "\n",
    "#function for removing HTML Tags\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "#function for counting the words in the train dataset\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in train[\"text\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "\n",
    "#function for removing the most frequent words\n",
    "cnt.most_common(10)\n",
    "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "\n",
    "#function for removing the most rare words\n",
    "n_rare_words = 10\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rarewords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "#remove emojis\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "#function for removing duplicate white spaces\n",
    "def remove_duplicate_ws(x):\n",
    "  x=str(x)\n",
    "  x=\" \".join(re.split(\"\\s+\", x, flags=re.UNICODE))\n",
    "  return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(input_data, text_col):\n",
    "    #convert all the input texts into lower case.\n",
    "  input_data[\"text_col_clean\"]=input_data[text_col].apply(lambda x:str(x).lower())\n",
    "  #convert all the shortform of the input texts to its expanded form.\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:[expanded_form(t) for t in str(x).split()])\n",
    "  #remove the stopwords based on spacy default package\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:[t for t in x if t not in spacy_stopwords])\n",
    "  #remove the url, punctuations and digits from the input text\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:clean_with_re(x))\n",
    "  #remove the HTML Tags from the input text\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_html(x))\n",
    "  #lemmatization - converting evary word to it's root form\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:\" \".join([t.lemma_ for t in spacy_model(str(x))if t.lemma_ !=\"-PRON-\" ]))\n",
    "  #remove the most frequents words\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_freqwords(x))\n",
    "  #remove the most rare words\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_rarewords(x))\n",
    "  #remove the emojis\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_emoji(x))\n",
    "  #remove the duplicate whitespace.\n",
    "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_duplicate_ws(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the pre_processing function both for train and test datasets\n",
    "pre_processing(input_data=train, text_col=\"text\")\n",
    "pre_processing(input_data=test, text_col=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pre-processing:   but my bday is JUNE 19.. this is wack... and ihavent seen any promotions for my bday party  someone better finagle this asap!\n",
      "After Pre-processing:  bday june wack have not see promotion bday party well finagle asap\n",
      "Before Pre-processing:  23\n",
      "After Pre-processing:  12\n",
      "Sentiment of the text:  0\n"
     ]
    }
   ],
   "source": [
    "#check random text before and after pre-processing\n",
    "print(\"Before Pre-processing: \",train[\"text\"][300])\n",
    "print(\"After Pre-processing: \",train[\"text_col_clean\"][300])\n",
    "#print the sentence length before and after pre-processing\n",
    "print(\"Before Pre-processing: \",len(train[\"text\"][300].split()))\n",
    "print(\"After Pre-processing: \",len(train[\"text_col_clean\"][300].split()))\n",
    "#print the sentiment of the text\n",
    "print(\"Sentiment of the text: \",train[\"label\"][300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset\n",
    "train = train[['text_col_clean','label']]\n",
    "test = test[['text_col_clean','label']]\n",
    "\n",
    "# #sanity check\n",
    "# train.head()\n",
    "# test.head()\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()\n",
    "\n",
    "# #reduce the sample size inorder to save time for our experiment.\n",
    "# train = train.sample(n=1000)\n",
    "# test = test.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset and split into train and val dataset\n",
    "train_data, val_data = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# perparameters\n",
    "learning_rate = 2e-5\n",
    "max_length = 128\n",
    "batch_size = 8\n",
    "num_labels = 2\n",
    "epochs = 10\n",
    "\n",
    "pretrained_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.iloc[index]['text_col_clean'] # neec to change based on text pre-processing\n",
    "        label = self.data.iloc[index]['label']\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text, \n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt')\n",
    "        return encoding['input_ids'][0], encoding['attention_mask'][0], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and data loaders for train val and test\n",
    "train_dataset = MyDataset(train_data, tokenizer, max_length)\n",
    "val_dataset = MyDataset(val_data, tokenizer, max_length)\n",
    "test_dataset = MyDataset(test, tokenizer, max_length)\n",
    "\n",
    "\n",
    "# #sanity check\n",
    "# train_dataset[5]\n",
    "# val_dataset[5]\n",
    "# test_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule):\n",
    "    def __init__(self, num_labels, batch_size, learning_rate):\n",
    "        super().__init__()\n",
    "        self.model = pretrained_model\n",
    "        self.num_classes = num_labels\n",
    "        self.loss_function = loss_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "           \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return output.logits\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        output = self(input_ids, attention_mask)\n",
    "        loss = self.loss_function(output, label)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        \n",
    "        #matrix calculation\n",
    "        accuracy = binary_accuracy(preds, label)\n",
    "        # f1_score = binary_f1_score(preds, label)\n",
    "        # recall = binary_recall(preds, label)\n",
    "        # precision = binary_precision(preds, label)\n",
    "        \n",
    "        #log the metrics\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_accuracy\", accuracy, prog_bar=True, logger=True)\n",
    "        # self.log(\"train_f1\", f1_score, prog_bar=True, logger=True)\n",
    "        # self.log(\"train_recall\", recall, prog_bar=True, logger=True)\n",
    "        # self.log(\"train_precision\", precision, prog_bar=True, logger=True)\n",
    "        return {\"train_loss\":loss, \"train_accuracy\":accuracy}\n",
    "\n",
    "           \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        output = self(input_ids, attention_mask)\n",
    "        loss = self.loss_function(output, label)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        \n",
    "        #matrix calculation\n",
    "        accuracy = binary_accuracy(preds, label)\n",
    "        # f1_score = binary_f1_score(preds, label)\n",
    "        # recall = binary_recall(preds, label)\n",
    "        # precision = binary_precision(preds, label)\n",
    "        \n",
    "        #log the metrics\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_accuracy\", accuracy, prog_bar=True, logger=True)\n",
    "        # self.log(\"val_f1\", f1_score, prog_bar=True, logger=True)\n",
    "        # self.log(\"val_recall\", recall, prog_bar=True, logger=True)\n",
    "        # self.log(\"val_precision\", precision, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\":loss, \"val_accuracy\":accuracy}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        output = self(input_ids, attention_mask)\n",
    "        loss = self.loss_function(output, label)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        \n",
    "        #matrix calculation\n",
    "        accuracy = binary_accuracy(preds, label)\n",
    "        f1_score = binary_f1_score(preds, label)\n",
    "        recall = binary_recall(preds, label)\n",
    "        precision = binary_precision(preds, label)\n",
    "        confusion_matrix = binary_confusion_matrix(preds, label)\n",
    "        confusion_matrix = confusion_matrix.cpu().detach().numpy()\n",
    "        \n",
    "        #plot confusion matrix        \n",
    "        df_cm = pd.DataFrame(confusion_matrix, index = range(2), columns=range(2))\n",
    "        plt.figure(figsize = (10,7))\n",
    "        fig_ = sns.heatmap(df_cm, annot=True, cmap='Spectral').get_figure()\n",
    "        plt.close(fig_)\n",
    "    \n",
    "        #log the metrics\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"test_accuracy\", accuracy, prog_bar=True, logger=True)\n",
    "        self.log(\"test_f1\", f1_score, prog_bar=True, logger=True)\n",
    "        self.log(\"test_recall\", recall, prog_bar=True, logger=True)\n",
    "        self.log(\"test_precision\", precision, prog_bar=True, logger=True)\n",
    "        self.logger.experiment.add_figure('confusion matrix', fig_, global_step=self.current_epoch)\n",
    "        return {\"test_loss\":loss, \"test_accuracy\":accuracy}\n",
    "          \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "            'monitor': 'val_loss'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#ensure full reproducibility from run to run\n",
    "seed_everything(42, workers=True)\n",
    "model = MyModel(num_labels, batch_size, learning_rate)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./best_model/',\n",
    "    filename='best_model'\n",
    ")\n",
    "\n",
    "# Custom loager. By default lightning_logs are generated. if you want to pass the custom logger then you have the pass logger=logger inside the trainer.\n",
    "# logger = TensorBoardLogger(\"logs/\", name=\"my_experiment\")\n",
    "\n",
    "# Early stoping\n",
    "# early_stop_callback = EarlyStopping(monitor=\"val_acc\", min_delta=0.00, patience=3, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=epochs, gpus=1, \n",
    "                     callbacks=[checkpoint_callback, LearningRateMonitor(), TQDMProgressBar(refresh_rate=5)], auto_lr_find=True, deterministic=True, auto_scale_batch_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "Batch size 256 failed, trying batch size 128\n",
      "Finished batch size finder, will continue with full run using batch size 128\n",
      "Restoring states from the checkpoint path at /home/gist/wahid/.scale_batch_size_6d90c6d8-2885-475a-b036-7619bc718756.ckpt\n",
      "Restored all states from the checkpoint file at /home/gist/wahid/.scale_batch_size_6d90c6d8-2885-475a-b036-7619bc718756.ckpt\n"
     ]
    }
   ],
   "source": [
    "# fine the batch size automatically and update the model\n",
    "new_batch_size = trainer.tuner.scale_batch_size(model, mode='power')\n",
    "model.batch_size = new_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008c7dfd70934060922f34348b37c665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 92 steps due to diverging loss.\n",
      "Restoring states from the checkpoint path at /home/gist/wahid/.lr_find_0715c713-151f-4eaf-bbfb-b4cb957e43ee.ckpt\n",
      "Restored all states from the checkpoint file at /home/gist/wahid/.lr_find_0715c713-151f-4eaf-bbfb-b4cb957e43ee.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [1e-08, 1.4454397707459274e-08, 1.7378008287493753e-08, 2.0892961308540398e-08, 2.51188643150958e-08, 3.019951720402016e-08, 3.630780547701014e-08, 4.36515832240166e-08, 5.248074602497726e-08, 6.309573444801934e-08, 7.585775750291837e-08, 9.120108393559096e-08, 1.0964781961431852e-07, 1.3182567385564074e-07, 1.5848931924611133e-07, 1.9054607179632475e-07, 2.2908676527677735e-07, 2.7542287033381663e-07, 3.311311214825911e-07, 3.9810717055349735e-07, 4.786300923226383e-07, 5.75439937337157e-07, 6.918309709189366e-07, 8.317637711026709e-07, 1e-06, 1.2022644346174132e-06, 1.445439770745928e-06, 1.7378008287493761e-06, 2.089296130854039e-06, 2.5118864315095797e-06, 3.0199517204020163e-06, 3.630780547701014e-06, 4.365158322401661e-06, 5.248074602497728e-06, 6.3095734448019305e-06, 7.585775750291836e-06, 9.120108393559096e-06, 1.0964781961431852e-05, 1.3182567385564076e-05, 1.584893192461114e-05, 1.9054607179632464e-05, 2.2908676527677725e-05, 2.7542287033381663e-05, 3.311311214825911e-05, 3.9810717055349735e-05, 4.786300923226385e-05, 5.7543993733715664e-05, 6.918309709189363e-05, 8.317637711026709e-05, 0.0001, 0.00012022644346174131, 0.0001445439770745928, 0.00017378008287493763, 0.0002089296130854041, 0.0002511886431509582, 0.0003019951720402019, 0.000363078054770101, 0.0004365158322401656, 0.0005248074602497723, 0.000630957344480193, 0.0007585775750291836, 0.0009120108393559097, 0.0010964781961431851, 0.0013182567385564075, 0.001584893192461114, 0.0019054607179632484, 0.0022908676527677745, 0.002754228703338169, 0.003311311214825908, 0.003981071705534969, 0.00478630092322638, 0.005754399373371567, 0.006918309709189364, 0.008317637711026709, 0.01, 0.012022644346174132, 0.01445439770745928, 0.017378008287493765, 0.02089296130854041, 0.025118864315095822, 0.030199517204020192, 0.036307805477010104, 0.04365158322401657, 0.05248074602497723, 0.0630957344480193, 0.07585775750291836, 0.09120108393559097, 0.10964781961431852, 0.13182567385564073, 0.15848931924611143, 0.19054607179632482, 0.2290867652767775], 'loss': [0.3979947530862052, 0.532605532172131, 0.5988695992133362, 0.6401848613962846, 0.6658833875536296, 0.6757719325812924, 0.6877843115964172, 0.6997848150995634, 0.7105719779053353, 0.7142464596734656, 0.7173682683877415, 0.720854495479987, 0.7253401332191877, 0.7273547642618813, 0.7300765721985722, 0.7302418358430086, 0.7359383736118904, 0.7381304631851294, 0.7405671099479025, 0.7407888468635744, 0.7406904325016072, 0.7379982808661929, 0.7372578293611721, 0.7351094756595614, 0.7374254667195175, 0.7359419719686106, 0.7373761891685631, 0.7384960495272889, 0.7394985775543012, 0.7383208842733328, 0.7375405030666742, 0.7370943859940399, 0.7368367034344592, 0.7349794208474327, 0.7342134228851931, 0.7321229337384318, 0.7311512443949736, 0.7291539788800929, 0.7272342545650031, 0.7260898451493727, 0.7236537413992756, 0.7220240980739433, 0.7201290265801075, 0.7171981794408291, 0.7139857244832196, 0.7105099961256099, 0.706528926255051, 0.7034481328298003, 0.6975417174383814, 0.6936455733270567, 0.6872736834129879, 0.6811784269352894, 0.6738127675740191, 0.6640869704557391, 0.6529189872846506, 0.6448671008193759, 0.6338325397577296, 0.6259198627324272, 0.6214814512690211, 0.6234460400153301, 0.6241841420928815, 0.6229144963230817, 0.623355486501091, 0.6345122429289086, 0.6339187192731688, 0.6359132227625721, 0.643604684831094, 0.6555499876080237, 0.6582790030095733, 0.6620321791598212, 0.6730188095923043, 0.7132993684947553, 0.7153013299645197, 0.714710533710852, 0.7179970781628464, 0.7326429296126421, 0.750459744888309, 0.7582584482880264, 0.7710563980361894, 0.7801440070444254, 0.7977944836490128, 0.8334261821440674, 0.8690100646521834, 0.8740690614550682, 0.9437628578076913, 1.0176930139666953, 1.024437241506939, 1.1958131255411573, 1.2955505724154726, 1.384831385462442, 1.5418940021374918, 1.8043753644071132]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run learning rate finder\n",
    "lr_finder = trainer.tuner.lr_find(model)\n",
    "\n",
    "# Results can be found in\n",
    "print(lr_finder.results)\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new learning rate:  0.0002089296130854041\n"
     ]
    }
   ],
   "source": [
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "print(\"new learning rate: \", new_lr)\n",
    "\n",
    "# # update hparams of the model\n",
    "# model.hparams.lr = new_lr\n",
    "\n",
    "#updat the learning rate of the model\n",
    "model.configure_optimizers = lambda: optim.Adam(model.parameters(), lr=new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type                          | Params\n",
      "----------------------------------------------------------------\n",
      "0 | model         | BertForSequenceClassification | 109 M \n",
      "1 | loss_function | CrossEntropyLoss              | 0     \n",
      "----------------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2557e244821b42cf85569f39e284b86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a70623cf554391a349e124ef52e24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd08f17708f042e5bfa7347e015571fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915913aa03094602afbb59987d66adeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c9d26180cc42a0b1f791073eb47d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a064756ec9654c07981b0609d1941d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea86e3dfdfe64ce5a126bae12a67acdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d6dde14a46413d8563c9e4ccdb33da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13406a7a66147269eae523b0aecd915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2085234fea2d49778e991da95130b27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8af6253dd90415db14edfb8edd1a3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bcc1c95acd4c34b8b62eacec8f03df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# Training: This is the basic use of the trainer\n",
    "trainer.fit(model, model.train_dataloader(), model.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf93c2f3afa40c7b968a77fc664bd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Validate metric           DataLoader 0\n",
      "\n",
      "      val_accuracy          0.8628125190734863\n",
      "        val_loss            0.5318986773490906\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.5318986773490906, 'val_accuracy': 0.8628125190734863}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation: Perform an evaluation epoch over the validation set, outside of the training loop\n",
    "trainer.validate(model, model.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0ac462d5ac4f619007ce4b9f4ac031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "      test_accuracy            0.89794921875\n",
      "         test_f1            0.9012746810913086\n",
      "        test_loss           0.2594478130340576\n",
      "     test_precision         0.9016696214675903\n",
      "       test_recall           0.902188777923584\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2594478130340576,\n",
       "  'test_accuracy': 0.89794921875,\n",
       "  'test_f1': 0.9012746810913086,\n",
       "  'test_recall': 0.902188777923584,\n",
       "  'test_precision': 0.9016696214675903}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model checkpoint for testing\n",
    "best_model = MyModel.load_from_checkpoint(checkpoint_callback.best_model_path, num_labels=num_labels, batch_size=batch_size, learning_rate=learning_rate)\n",
    "\n",
    "# Test the model using the test loader\n",
    "trainer.test(best_model, model.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this \"tensorboard --logdir=lightning_logs/\" in the terminal to see the logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wahid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
