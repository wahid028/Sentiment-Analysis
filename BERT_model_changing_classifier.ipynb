{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "BERT model_changing classifier.ipynb",
      "authorship_tag": "ABX9TyNijzrA3BCzgXDtV8iWAjbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wahid028/Sentiment-Analysis/blob/main/BERT_model_changing_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "EJTWvIVCtLHI",
        "outputId": "18886218-1ed1-4927-a2f0-8782094c13e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-56e584a6-1678-4874-ab95-94f98f9faa0d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-56e584a6-1678-4874-ab95-94f98f9faa0d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "#install kaggle\n",
        "!pip install -q kaggle\n",
        "\n",
        "#upload the kaggle.json file\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "#create a kaggle directory\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "#copy the kaggle.json to kaggle directory\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "#permission for the json to act\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c tweet-sentiment-extraction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAFIG1PkuWTB",
        "outputId": "156689ed-f67c-4ba6-a1ee-e0f2f2d59bbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tweet-sentiment-extraction.zip to /content\n",
            " 72% 1.00M/1.39M [00:00<00:00, 1.14MB/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 1.48MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tweet-sentiment-extraction.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBCDsrkrxkDM",
        "outputId": "d2a5739f-f742-4b29-c963-604634bbc2fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tweet-sentiment-extraction.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "rQyupsGTcT0s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk\n",
        "! pip install spacy\n",
        "! pip install beautifulsoup4\n",
        "! pip install regex"
      ],
      "metadata": {
        "id": "b80YkYK6cXBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb58f9d-ec89-4dc3-eaa2-9524e7aac5c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.11)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "nMZCPBr6H5gV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fe5fff-a4ce-43f2-e1f2-4b6bfca3dc54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "v2HQVEYQO0ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print bold text\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "metadata": {
        "id": "LgLvsP4yyYTD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download(\"all\")\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "pFooEGOix0iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528666a0-850d-4a2e-c42b-890e43e1a867"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MCAioxxitho",
        "outputId": "c587756b-f3ad-4df2-824e-aabb713a7120"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4dIMLgJitJq",
        "outputId": "a8af7b2d-9afe-498d-a330-c002a56c7e3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../content/train.csv')"
      ],
      "metadata": {
        "id": "l6RbMDUxx5Yd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AP-IHam-dyoR",
        "outputId": "63119122-f26d-46eb-c2d8-484755f3fda2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  \n",
              "0  I`d have responded, if I were going   neutral  \n",
              "1                             Sooo SAD  negative  \n",
              "2                          bullying me  negative  \n",
              "3                       leave me alone  negative  \n",
              "4                        Sons of ****,  negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b148299c-379a-4cfe-94a4-30ee585dfafd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b148299c-379a-4cfe-94a4-30ee585dfafd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b148299c-379a-4cfe-94a4-30ee585dfafd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b148299c-379a-4cfe-94a4-30ee585dfafd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the rows with neutral sentiment as we are only interested in positive and negative sentiment\n",
        "df = df[df['sentiment'] != 'neutral']\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "DDDvMPd2eiJr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['text','sentiment']]"
      ],
      "metadata": {
        "id": "u1FDXKsxd5-g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment converter\n",
        "def sentiment_ts(sentiment):\n",
        "    if sentiment == 'negative':\n",
        "        return 0\n",
        "    elif sentiment == 'positive':\n",
        "        return 1\n",
        "    \n",
        "df['label'] = df['sentiment'].apply(sentiment_ts)"
      ],
      "metadata": {
        "id": "v7-vt2cNd-PR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pYLA2CCxeJLh",
        "outputId": "34b9d8cd-046c-4985-c00a-0637c299b4f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text sentiment  label\n",
              "0      Sooo SAD I will miss you here in San Diego!!!  negative      0\n",
              "1                          my boss is bullying me...  negative      0\n",
              "2                     what interview! leave me alone  negative      0\n",
              "3   Sons of ****, why couldn`t they put them on t...  negative      0\n",
              "4  2am feedings for the baby are fun when he is a...  positive      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd1b4f6a-99e7-4405-bb9b-dcc28066e9f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2am feedings for the baby are fun when he is a...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd1b4f6a-99e7-4405-bb9b-dcc28066e9f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd1b4f6a-99e7-4405-bb9b-dcc28066e9f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd1b4f6a-99e7-4405-bb9b-dcc28066e9f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['text','label']]"
      ],
      "metadata": {
        "id": "ACoL0E41exDX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Pre-processing"
      ],
      "metadata": {
        "id": "mger_l3ce4Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the spacy model and functions related to stop words modification\n",
        "spacy_model = spacy.load('en_core_web_sm')\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as spacy_stopwords\n",
        "# print(spacy_model.Defaults.stop_words) #print the default stop words list\n",
        "# spacy_model.Defaults.stop_words.remove(\"whatever\") #remove single stop word from the list\n",
        "# spacy_model.Defaults.stop_words -= {\"whatever\", \"whenever\"} #remove several stop words from the list\n",
        "spacy_model.Defaults.stop_words.add(\"4am\") #add single stop word in the default list\n",
        "# spacy_model.stop_words |= {\"my_new_stopword1\",\"my_new_stopword2\"} #add several stop words in the default list"
      ],
      "metadata": {
        "id": "ye-xKPA9e9Mk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#most widely used shortforms are in the internet for social media data\n",
        "contra_Expan_Dict = {\n",
        "\"ain`t\": \"am not\",\"aren`t\": \"are not\",\"can`t\": \"cannot\",\"can`t`ve\": \"cannot have\",\"`cause\": \"because\",\n",
        "\"could`ve\": \"could have\",\"couldn`t\": \"could not\",\"couldn`t`ve\": \"could not have\",\"didn`t\": \"did not\",\n",
        "\"doesn`t\": \"does not\",\"don`t\": \"do not\",\"hadn`t\": \"had not\",\"hadn`t`ve\": \"had not have\",\"hasn`t\": \"has not\",\n",
        "\"haven`t\": \"have not\",\"he`d\": \"he would\",\"he`d`ve\": \"he would have\",\"he`ll\": \"he will\",\"he`ll`ve\": \"he will have\",\n",
        "\"he`s\": \"he is\",\"how`d\": \"how did\",\"how`d`y\": \"how do you\",\"how`ll\": \"how will\",\n",
        "\"how`s\": \"how does\",\"i`d\": \"i would\",\"i`d`ve\": \"i would have\",\"i`ll\": \"i will\",\"i`ll`ve\": \"i will have\",\"i`m\": \"i am\",\n",
        "\"i`ve\": \"i have\",\"isn`t\": \"is not\",\"it`d\": \"it would\",\"it`d`ve\": \"it would have\",\"it`ll\": \"it will\",\"it`ll`ve\": \"it will have\",\n",
        "\"it`s\": \"it is\",\"let`s\": \"let us\",\"ma`am\": \"madam\",\"mayn`t\": \"may not\",\"might`ve\": \"might have\",\"mightn`t\": \"might not\",\n",
        "\"mightn`t`ve\": \"might not have\",\"must`ve\": \"must have\",\"mustn`t\": \"must not\",\"mustn`t`ve\": \"must not have\",\"needn`t\": \"need not\",\"needn`t`ve\": \"need not have\",\n",
        "\"o`clock\": \"of the clock\",\"oughtn`t\": \"ought not\",\"oughtn`t`ve\": \"ought not have\",\"shan`t\": \"shall not\",\n",
        "\"sha`n`t\": \"shall not\",\"shan`t`ve\": \"shall not have\",\"she`d\": \"she would\",\n",
        "\"she`d`ve\": \"she would have\",\"she`ll\": \"she will\",\"she`ll`ve\": \"she will have\",\n",
        "\"she`s\": \"she is\",\"should`ve\": \"should have\",\"shouldn`t\": \"should not\",\"shouldn`t`ve\": \"should not have\",\"so`ve\": \"so have\",\"so`s\": \"so is\",\n",
        "\"that`d\": \"that would\",\"that`d`ve\": \"that would have\",\"that`s\": \"that is\",\"there`d\": \"there would\",\"there`d`ve\": \"there would have\",\"there`s\": \"there is\",\n",
        "\"they`d\": \"they would\",\"they`d`ve\": \"they would have\",\"they`ll\": \"they will\",\"they`ll`ve\": \"they will have\",\"they`re\": \"they are\",\"they`ve\": \"they have\",\n",
        "\"to`ve\": \"to have\",\"wasn`t\": \"was not\",\" u \": \" you \",\" ur \": \" your \",\" n \": \" and \",\"won`t\": \"would not\",\n",
        "\"dis\": \"this\",\"bak\": \"back\",\"brng\": \"bring\",\"sooo\": \"so\", \"afaik\" :\"as far as i know\",\n",
        "\"afk\" :\"away from keyboard\",\"asap\" :\"as soon as possible\",\"atk\" :\"at the keyboard\",\"atm\" :\"at the moment\",\"a3\" :\"anytime, anywhere, anyplace\",\n",
        "\"bak\" :\"back at keyboard\",\"bbl\" :\"be back later\",\"bbs\" :\"be back soon\",\"bfn\" :\"bye for now\",\"b4n\" :\"bye for now\",\"brb\" :\"be right back\",\n",
        "\"brt\" :\"be right there\",\"btw\" :\"by the way\",\"b4\" :\"before\",\"b4n\" :\"bye for now\",\"cu\" :\"see you\",\"cul8r\" :\"see you later\",\n",
        "\"cya\" :\"see you\",\"faq\" :\"frequently asked questions\",\"fc\" :\"fingers crossed\",\"fwiw\" :\"for what it's worth\",\"fyi\" :\"for your information\",\n",
        "\"gal\" :\"get a life\",\"gg\" :\"good game\",\"gn\" :\"good night\",\"gmta\" :\"great minds think alike\",\"gr8\" :\"great!\",\"g9\" :\"genius\",\n",
        "\"ic\" :\"i see\",\"icq\" :\"i seek you (also a chat program)\",\"ilu\" :\"ilu: i love you\",\"imho\" :\"in my honest/humble opinion\",\"imo\" :\"in my opinion\",\"iow\" :\"in other words\",\n",
        "\"irl\" :\"in real life\",\"kiss\" :\"keep it simple, stupid\",\"ldr\" :\"long distance relationship\",\"lmao\" :\"laugh my a.. off\",\"lol\" :\"laughing out loud\",\n",
        "\"ltns\" :\"long time no see\",\"l8r\" :\"later\",\"mte\" :\"my thoughts exactly\",\"m8\" :\"mate\",\"nrn\" :\"no reply necessary\",\"oic\" :\"oh i see\",\n",
        "\"pita\" :\"pain in the a..\",\"prt\" :\"party\",\"prw\" :\"parents are watching\",\"qpsa?   que pasa?\" :\"\",\"rofl\" :\"rolling on the floor laughing\",\n",
        "\"roflol\" :\"rolling on the floor laughing out loud\",\"rotflmao\" :\"rolling on the floor laughing my ass off\",\"sk8\" :\"skate\",\"stats\" :\"your sex and age\",\n",
        "\"asl\" :\"age, sex, location\",\"thx\" :\"thank you\",\"ttfn\" :\"ta-ta for now!\",\"ttyl\" :\"talk to you later\",\n",
        "\"u\" :\"you\",\"u2\" :\"you too\",\"u4e\" :\"yours for ever\",\"wb\" :\"welcome back\",\"wtf\" :\"what the fuck\",\"wtg\" :\"way to go!\",\n",
        "\"wuf\" :\"where are you from?\",\"w8\" :\"wait\",\"7k\" :\"sick:-d laugher\", \"w/out\": \"without\", \"ihavent\": \"i have not\", \"bday\": \"birthday\", \"im\": \"i am\"}"
      ],
      "metadata": {
        "id": "fsOmLYL3fDkw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for converting shortforms to it's expanded form based on contra_Expan_Dict\n",
        "def expanded_form(x):\n",
        "  if x in contra_Expan_Dict.keys():\n",
        "    return(contra_Expan_Dict[x])\n",
        "  else:\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "_poEqbeafFHo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for removing url punctuations and digits\n",
        "def clean_with_re(x):\n",
        "  x=str(x)\n",
        "  x=re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\" \", x) #Remove URLs\n",
        "  x=re.sub(r'[^\\w ]+', \"\", x) # Remove Punctuation-1\n",
        "  x=re.sub(r\"[,!@&\\'?\\.$%_]\",\" \", x) # Remove Punctuation-2\n",
        "  x=re.sub(r\"\\d+\",\" \", x) #Remove digits\n",
        "  return(x)"
      ],
      "metadata": {
        "id": "XpMgJ1PCfJ0f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for removing HTML Tags\n",
        "def remove_html(text):\n",
        "    return BeautifulSoup(text, \"lxml\").text"
      ],
      "metadata": {
        "id": "A2F199rCfMPH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for counting the words\n",
        "from collections import Counter\n",
        "cnt = Counter()\n",
        "for text in df[\"text\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1\n",
        "\n",
        "#function for removing the most frequent words\n",
        "cnt.most_common(10)\n",
        "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
        "def remove_freqwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
        "\n",
        "#function for removing the most rare words\n",
        "n_rare_words = 10\n",
        "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
        "def remove_rarewords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])"
      ],
      "metadata": {
        "id": "ax_5b6CBfPR6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove emojis\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ],
      "metadata": {
        "id": "i_4Ur-FefR-J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for removing duplicate white spaces\n",
        "def remove_duplicate_ws(x):\n",
        "  x=str(x)\n",
        "  x=\" \".join(re.split(\"\\s+\", x, flags=re.UNICODE))\n",
        "  return(x)"
      ],
      "metadata": {
        "id": "8jvAJZ9QfUms"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processing(input_data, text_col):\n",
        "  #convert all the input texts into lower case.\n",
        "  input_data[\"text_col_clean\"]=input_data[text_col].apply(lambda x:str(x).lower())\n",
        "  #convert all the shortform of the input texts to its expanded form.\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:[expanded_form(t) for t in str(x).split()])\n",
        "  #remove the stopwords based on spacy default package\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:[t for t in x if t not in spacy_stopwords])\n",
        "  #remove the url, punctuations and digits from the input text\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:clean_with_re(x))\n",
        "  #remove the HTML Tags from the input text\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_html(x))\n",
        "  #lemmatization - converting evary word to it's root form\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:\" \".join([t.lemma_ for t in spacy_model(str(x))if t.lemma_ !=\"-PRON-\" ]))\n",
        "  #remove the most frequents words\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_freqwords(x))\n",
        "  #remove the most rare words\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_rarewords(x))\n",
        "  #remove the emojis\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_emoji(x))\n",
        "  #remove the duplicate whitespace.\n",
        "  input_data[\"text_col_clean\"]=input_data[\"text_col_clean\"].apply(lambda x:remove_duplicate_ws(x))"
      ],
      "metadata": {
        "id": "ZXxixtSofXcg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call the pre_processing function\n",
        "pre_processing(input_data=df, text_col=\"text\")"
      ],
      "metadata": {
        "id": "txX0_J5xfaL7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check random text before and after pre-processing\n",
        "print(\"Before Pre-processing: \",df[\"text\"][401])\n",
        "print(\"After Pre-processing: \",df[\"text_col_clean\"][401])\n",
        "#print the sentence length before and after pre-processing\n",
        "print(\"Before Pre-processing: \",len(df[\"text\"][401].split()))\n",
        "print(\"After Pre-processing: \",len(df[\"text_col_clean\"][401].split()))\n",
        "#print the sentiment of the text\n",
        "print(\"Sentiment of the text: \",df[\"label\"][401])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_FW4eexfgKJ",
        "outputId": "0f0146f6-3e3c-4b38-d212-69706c9e0dd4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Pre-processing:   ...i`m sorry about you are still sick  u know most of them, AND i know that u will guess the 'pelzer present' ;-)\n",
            "After Pre-processing:  m sorry sick know they know guess pelzer present\n",
            "Before Pre-processing:  23\n",
            "After Pre-processing:  9\n",
            "Sentiment of the text:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new dataset for further processing"
      ],
      "metadata": {
        "id": "amX1UV3DfiwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create new dataframe with text_col_clean and label\n",
        "df_new = df[['text_col_clean','label']]\n",
        "df_new.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kvjj9o7rfpIP",
        "outputId": "a4ef4ddc-6e83-4fc4-c63d-10821083f84a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  text_col_clean  label\n",
              "0             sad miss san diego      0\n",
              "1                     boss bully      0\n",
              "2                interview leave      0\n",
              "3      son could not release buy      0\n",
              "4  be feeding baby fun smile coo      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9886cba1-8d4a-4949-8b9f-4eb545e88dba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_col_clean</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sad miss san diego</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>boss bully</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>interview leave</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>son could not release buy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>be feeding baby fun smile coo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9886cba1-8d4a-4949-8b9f-4eb545e88dba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9886cba1-8d4a-4949-8b9f-4eb545e88dba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9886cba1-8d4a-4949-8b9f-4eb545e88dba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the NA values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqiGpBJUtTwt",
        "outputId": "e453e001-d40f-4b2d-db84-be556f0e534c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text              0\n",
              "label             0\n",
              "text_col_clean    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data set into required data type\n",
        "df_new['text_col_clean'] = df_new['text_col_clean'].astype(str)\n",
        "df_new['label'] = df_new['label'].astype('int32')"
      ],
      "metadata": {
        "id": "to2Gd3-Ksy_7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az_Vubzotvvy",
        "outputId": "e8160fac-37fa-4540-eaba-6c88c1fc28b4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text_col_clean    object\n",
              "label              int32\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how much memore is used for the dataset\n",
        "print(\"'\\n==== For initial dataset ====\\n'\")\n",
        "print(df.memory_usage(deep=True))\n",
        "printmd('**Total memory usage:**')\n",
        "print(df.memory_usage().sum())\n",
        "print(\"'\\n==== For updated dataset ====\\n'\")\n",
        "print(df_new.memory_usage(deep=True))\n",
        "printmd('**Total memory usage:**')\n",
        "print(df_new.memory_usage().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "7Yz7viyzuSK_",
        "outputId": "bf902411-e742-49ab-abe3-93baf6d5c4b7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'\n",
            "==== For initial dataset ====\n",
            "'\n",
            "Index                 128\n",
            "text              2087368\n",
            "label              130904\n",
            "text_col_clean    1597122\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Total memory usage:**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "392840\n",
            "'\n",
            "==== For updated dataset ====\n",
            "'\n",
            "Index                 128\n",
            "text_col_clean    1597122\n",
            "label               65452\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Total memory usage:**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #delete the original dataframe\n",
        "# del df\n",
        "\n",
        "# #check the gpu memory usage\n",
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "ybACBxE2fw14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df_new.text_col_clean.values\n",
        "labels = df_new.label.values"
      ],
      "metadata": {
        "id": "O0ePGPlXfzZ8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset"
      ],
      "metadata": {
        "id": "P4VNviejf0qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_new['text_col_clean']\n",
        "y = df_new['label']\n",
        "\n",
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(X, y, random_state=2018, test_size=0.3, stratify=y)\n",
        "# split validation dataset into validation and test sets\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, random_state=2018, test_size=0.5, stratify=temp_labels)"
      ],
      "metadata": {
        "id": "lVBkl3xyjZ5u"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_text)"
      ],
      "metadata": {
        "id": "OjWpNtbKfdMG",
        "outputId": "2fcee4be-18b5-49fd-da24-9c56b35e6609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2455"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "print(\"Mean length of sentence: \",np.mean(seq_len))\n",
        "print(\"Max length of sentence: \",max (seq_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "uyym1XIGf4br",
        "outputId": "c076c986-5488-4b79-b407-31d26505e37f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean length of sentence:  7.261917234154008\n",
            "Max length of sentence:  26\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokeninzation and Encoding"
      ],
      "metadata": {
        "id": "1UN_t5lBj1M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import tokenizer\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "model_ckpt = \"bert-base-uncased\"\n",
        "num_labels = 2 #need to modify based on our dataset (positive, negative, neutral)\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(model_ckpt, do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJapWviHj6f6",
        "outputId": "03b62c93-4485-4d85-8348-9b98451e48ed"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set, validation set and test set\n",
        "\n",
        "max_length = 64\n",
        "\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_length,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_length,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_length,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "id": "7FGkQe9wf8h6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "bVvcGorykSxq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "validation_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "prediction_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "\n",
        "# sampler for sampling the data during testing\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "JcGJgKx4kWZU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the tokenizer is working or not\n",
        "\n",
        "# Print the original sentence.\n",
        "print('Original: ', sentences[401])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[401]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[401])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDQx33qikZ68",
        "outputId": "b86d6624-83e0-4143-a1b2-f2554e92967d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  m sorry sick know they know guess pelzer present\n",
            "Tokenized:  ['m', 'sorry', 'sick', 'know', 'they', 'know', 'guess', 'pe', '##lz', '##er', 'present']\n",
            "Token IDs:  [1049, 3374, 5305, 2113, 2027, 2113, 3984, 21877, 23858, 2121, 2556]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom model"
      ],
      "metadata": {
        "id": "42HAIQdfNfig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Np1QvLygNeVd"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "voSnDaotNqzI",
        "outputId": "7b6788d4-b6e1-418b-c387-9398a13e0b8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 176 µs, sys: 0 ns, total: 176 µs\n",
            "Wall time: 183 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=BertClassifier().to(device)"
      ],
      "metadata": {
        "id": "YXXRAvGMPJZE",
        "outputId": "7c3498b8-3fa2-4aa9-c9fa-27d803cf1a8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj9udjNuxE21",
        "outputId": "9b13ace1-a592-46a1-dd3e-a6188f299ccd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2ndps7xxI9H",
        "outputId": "7fff6810-fd09-485d-a856-55720d47cb5f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 203 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.0.weight                                        (50, 768)\n",
            "classifier.0.bias                                              (50,)\n",
            "classifier.2.weight                                          (2, 50)\n",
            "classifier.2.bias                                               (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer & Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "I55c8Alvy_Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "metadata": {
        "id": "_qwM8Pzac0U9"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "okmH5WjYzGMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "58MeAR_wzIHh"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "RGNDO26YzSqU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "o2R3yoRizYnP"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, validation_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "id": "QTbvVsL6cLCw",
        "outputId": "8e0d74eb-98d9-4089-8d28-633d78090c0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.641641   |     -      |     -     |   6.62   \n",
            "   1    |   40    |   0.409367   |     -      |     -     |   6.34   \n",
            "   1    |   60    |   0.318541   |     -      |     -     |   6.34   \n",
            "   1    |   80    |   0.319599   |     -      |     -     |   6.40   \n",
            "   1    |   100   |   0.319637   |     -      |     -     |   6.45   \n",
            "   1    |   120   |   0.298874   |     -      |     -     |   6.48   \n",
            "   1    |   140   |   0.275766   |     -      |     -     |   6.50   \n",
            "   1    |   160   |   0.295609   |     -      |     -     |   6.56   \n",
            "   1    |   180   |   0.276618   |     -      |     -     |   6.69   \n",
            "   1    |   200   |   0.305067   |     -      |     -     |   6.65   \n",
            "   1    |   220   |   0.303576   |     -      |     -     |   6.70   \n",
            "   1    |   240   |   0.302821   |     -      |     -     |   6.73   \n",
            "   1    |   260   |   0.267221   |     -      |     -     |   6.75   \n",
            "   1    |   280   |   0.292079   |     -      |     -     |   6.74   \n",
            "   1    |   300   |   0.267862   |     -      |     -     |   6.71   \n",
            "   1    |   320   |   0.246218   |     -      |     -     |   6.69   \n",
            "   1    |   340   |   0.285100   |     -      |     -     |   6.67   \n",
            "   1    |   357   |   0.288558   |     -      |     -     |   5.65   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.318601   |  0.253333  |   90.12   |  126.31  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.182054   |     -      |     -     |   6.96   \n",
            "   2    |   40    |   0.199450   |     -      |     -     |   6.66   \n",
            "   2    |   60    |   0.213454   |     -      |     -     |   6.66   \n",
            "   2    |   80    |   0.168688   |     -      |     -     |   6.69   \n",
            "   2    |   100   |   0.189058   |     -      |     -     |   6.69   \n",
            "   2    |   120   |   0.196843   |     -      |     -     |   6.69   \n",
            "   2    |   140   |   0.165151   |     -      |     -     |   6.70   \n",
            "   2    |   160   |   0.157901   |     -      |     -     |   6.70   \n",
            "   2    |   180   |   0.149294   |     -      |     -     |   6.70   \n",
            "   2    |   200   |   0.167469   |     -      |     -     |   6.69   \n",
            "   2    |   220   |   0.185003   |     -      |     -     |   6.69   \n",
            "   2    |   240   |   0.174255   |     -      |     -     |   6.68   \n",
            "   2    |   260   |   0.148940   |     -      |     -     |   6.69   \n",
            "   2    |   280   |   0.166488   |     -      |     -     |   6.68   \n",
            "   2    |   300   |   0.145484   |     -      |     -     |   6.67   \n",
            "   2    |   320   |   0.154033   |     -      |     -     |   6.68   \n",
            "   2    |   340   |   0.194251   |     -      |     -     |   6.67   \n",
            "   2    |   357   |   0.175587   |     -      |     -     |   5.65   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.174088   |  0.296496  |   89.92   |  128.28  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on Validation Set"
      ],
      "metadata": {
        "id": "F8a-53F0fVRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "-StzlV3AfS8y"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "X_VbpucvgTCE"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, validation_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, val_labels)"
      ],
      "metadata": {
        "id": "-NXIN_uTfmKq",
        "outputId": "1f14dd8a-3c60-40fa-cf1d-5a80a8cfc1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9611\n",
            "Accuracy: 89.89%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Our Model on the Entire Training Data"
      ],
      "metadata": {
        "id": "xGC1JYf_gl_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the train set and the validation set\n",
        "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
        "full_train_sampler = RandomSampler(full_train_data)\n",
        "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
        "\n",
        "# Train the Bert Classifier on the entire training data\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, full_train_dataloader, epochs=2)"
      ],
      "metadata": {
        "id": "foqo9ypqgm6v",
        "outputId": "9f122eab-7d06-456b-d22d-3fd8dbceb9ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.628894   |     -      |     -     |   6.61   \n",
            "   1    |   40    |   0.394825   |     -      |     -     |   6.31   \n",
            "   1    |   60    |   0.341266   |     -      |     -     |   6.36   \n",
            "   1    |   80    |   0.317997   |     -      |     -     |   6.42   \n",
            "   1    |   100   |   0.343848   |     -      |     -     |   6.47   \n",
            "   1    |   120   |   0.299944   |     -      |     -     |   6.51   \n",
            "   1    |   140   |   0.302724   |     -      |     -     |   6.53   \n",
            "   1    |   160   |   0.290827   |     -      |     -     |   6.58   \n",
            "   1    |   180   |   0.291436   |     -      |     -     |   6.62   \n",
            "   1    |   200   |   0.263179   |     -      |     -     |   6.66   \n",
            "   1    |   220   |   0.304123   |     -      |     -     |   6.70   \n",
            "   1    |   240   |   0.299629   |     -      |     -     |   6.74   \n",
            "   1    |   260   |   0.278229   |     -      |     -     |   6.75   \n",
            "   1    |   280   |   0.321640   |     -      |     -     |   6.75   \n",
            "   1    |   300   |   0.300709   |     -      |     -     |   6.72   \n",
            "   1    |   320   |   0.296175   |     -      |     -     |   6.69   \n",
            "   1    |   340   |   0.276026   |     -      |     -     |   6.68   \n",
            "   1    |   360   |   0.248042   |     -      |     -     |   6.66   \n",
            "   1    |   380   |   0.271367   |     -      |     -     |   6.65   \n",
            "   1    |   400   |   0.277663   |     -      |     -     |   6.65   \n",
            "   1    |   420   |   0.241606   |     -      |     -     |   6.67   \n",
            "   1    |   434   |   0.256461   |     -      |     -     |   4.57   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.151960   |     -      |     -     |   7.01   \n",
            "   2    |   40    |   0.156383   |     -      |     -     |   6.69   \n",
            "   2    |   60    |   0.194102   |     -      |     -     |   6.70   \n",
            "   2    |   80    |   0.149213   |     -      |     -     |   6.70   \n",
            "   2    |   100   |   0.176870   |     -      |     -     |   6.69   \n",
            "   2    |   120   |   0.176202   |     -      |     -     |   6.70   \n",
            "   2    |   140   |   0.192259   |     -      |     -     |   6.69   \n",
            "   2    |   160   |   0.178529   |     -      |     -     |   6.69   \n",
            "   2    |   180   |   0.124417   |     -      |     -     |   6.69   \n",
            "   2    |   200   |   0.196118   |     -      |     -     |   6.69   \n",
            "   2    |   220   |   0.170071   |     -      |     -     |   6.69   \n",
            "   2    |   240   |   0.161621   |     -      |     -     |   6.69   \n",
            "   2    |   260   |   0.203493   |     -      |     -     |   6.69   \n",
            "   2    |   280   |   0.155511   |     -      |     -     |   6.67   \n",
            "   2    |   300   |   0.164546   |     -      |     -     |   6.67   \n",
            "   2    |   320   |   0.176940   |     -      |     -     |   6.67   \n",
            "   2    |   340   |   0.199448   |     -      |     -     |   6.69   \n",
            "   2    |   360   |   0.135640   |     -      |     -     |   6.69   \n",
            "   2    |   380   |   0.210245   |     -      |     -     |   6.69   \n",
            "   2    |   400   |   0.143308   |     -      |     -     |   6.70   \n",
            "   2    |   420   |   0.170988   |     -      |     -     |   6.70   \n",
            "   2    |   434   |   0.165572   |     -      |     -     |   4.57   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    }
  ]
}